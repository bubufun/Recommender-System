{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =====Parameter Definition====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "data_root = os.path.abspath(os.getcwd())+ '/data/'\n",
    "#抓當前目錄的data資料夾\n",
    "\n",
    "raw_data_path = data_root + '/raw/'\n",
    "#當前目錄的data/raw/   此資料夾是放原始資料\n",
    "\n",
    "\n",
    "processed_data_path = data_root + '/processed/'\n",
    "#當前目錄的./data/processed/ 讀取處理過得資料檔\n",
    "\n",
    "\n",
    "keyword = 'CID_5' #請輸入要匯入的csv名稱\n",
    "\n",
    "\n",
    "# structurized csv files\n",
    "csv_path = processed_data_path + keyword + '.csv'\n",
    "#匯入./data/processed/keyword.csv 此處預設是爬蟲抓取好並初步整理好的欄位（未做清理和未做斷詞）\n",
    "\n",
    "\n",
    "# # Data Cleaning and Tokenizing\n",
    "w2v_csv_path = processed_data_path + keyword + '_w2v' + '.csv'\n",
    "#匯入全名./data/processed/keyword_w2v.csv 匯入已斷詞斷好並已清理的資料\n",
    "\n",
    "\n",
    "model_path = './models/'\n",
    "#./models/\n",
    "\n",
    "model_name = keyword + 'w2v_model_all.md'\n",
    "#幫moodel 取名為 keywordw2v_model_all.md\n",
    "\n",
    "if not os.path.isdir(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    print(\"made folder:\", model_path)\n",
    "#在當前目錄建立一個model資料夾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ===== Train & Save W2V models ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['862876', '935393', '1070050', '7443305']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['902396']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['1075820', '1116068', '5995609', '5995628', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['925607']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['915616', '915870', '916049', '925054', '9326...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words\n",
       "0         ['862876', '935393', '1070050', '7443305']\n",
       "1                                         ['902396']\n",
       "2  ['1075820', '1116068', '5995609', '5995628', '...\n",
       "3                                         ['925607']\n",
       "4  ['915616', '915870', '916049', '925054', '9326..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "import ast \n",
    "\n",
    "\n",
    "\n",
    "pd_corpus = pd.read_csv(w2v_csv_path)\n",
    "\n",
    "# Select Only unique documents\n",
    "corpus = pd.DataFrame(pd_corpus.words.sample(frac=1).unique(),\n",
    "                   columns=['words'])\n",
    "\n",
    "# type converting\n",
    "corpus.words = corpus.words.apply(lambda x: ast.literal_eval(x))\n",
    "# corpus.words = corpus.words.apply(lambda x: x.strip('][').split(', '))\n",
    "\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "model_path_cbow = model_path + model_name + '.' + 'cbow'\n",
    "model_path_sg = model_path + model_name + '.' + 'sg'\n",
    "\n",
    "model = Word2Vec(corpus.words,min_count=1)\n",
    "model.save(model_path_cbow)\n",
    "\n",
    "model = Word2Vec(corpus.words,sg=1,min_count=1)\n",
    "model.save(model_path_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path_cbow = model_path + model_name + '.' + 'cbow'\n",
    "# model_path_sg = model_path + model_name + '.' + 'sg'\n",
    "\n",
    "word2vec_sg = Word2Vec.load(model_path_sg)\n",
    "word2vec_cbow = Word2Vec.load(model_path_cbow)\n",
    "\n",
    "#=======================================================\n",
    "\n",
    "# keyword = 'BASKET'\n",
    "\n",
    "# from gensim.models.word2vec import Word2Vec\n",
    "# word2vec_sg = Word2Vec.load('./models/%sw2v_model_all.md.sg' % keyword)\n",
    "# word2vec_cbow = Word2Vec.load('./models/%sw2v_model_all.md.cbow'% keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'821138'\", 0.9867815971374512),\n",
       " (\"'862192'\", 0.9857413172721863),\n",
       " (\"'852679'\", 0.9856857061386108),\n",
       " (\"'859844'\", 0.9851423501968384),\n",
       " (\"'857854'\", 0.9849184155464172),\n",
       " (\"'859781'\", 0.9847391247749329),\n",
       " (\"'848022'\", 0.9832661747932434),\n",
       " (\"'833473'\", 0.9827028512954712),\n",
       " (\"'866902'\", 0.9813868999481201),\n",
       " (\"'846735'\", 0.9812468886375427)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_sg.wv.most_similar(\"'878913'\")\n",
    "# word2vec_sg.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ===== Connect to Embedding Projector ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tensorboard.plugins import projector\n",
    "import subprocess\n",
    "\n",
    "model_path_cbow = model_path + model_name + '.' + 'cbow'\n",
    "#./models/keywordw2v_model_all.md.cbow\n",
    "\n",
    "model_path_sg = model_path + model_name + '.' + 'sg'\n",
    "#./models/keywordw2v_model_all.md.sg\n",
    "\n",
    "\n",
    "model_dir = model_path\n",
    "log_dir = model_dir + 'embedding_log'\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "    \n",
    "metadata_name = 'metadata.tsv'\n",
    "\n",
    "# load model \n",
    "# model_file = model_dir + model_name\n",
    "word2vec = Word2Vec.load(model_path_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=199, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-73acbc2cafa5>:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  wv_dict['wv'].append(word2vec[word])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "wv_dict = {'words':[], 'counts':[], 'wv':[]}\n",
    "\n",
    "for word in word2vec.wv.vocab.keys():\n",
    "    if word2vec.wv.vocab[word].count > 5:\n",
    "        wv_dict['words'].append(word)\n",
    "        wv_dict['counts'].append(word2vec.wv.vocab[word].count)\n",
    "        wv_dict['wv'].append(word2vec[word])\n",
    "        \n",
    "pd_wv = pd.DataFrame(wv_dict)\n",
    "\n",
    "# write labels and count\n",
    "embedding = np.empty((len(pd_wv), word2vec.vector_size), dtype=np.float32)\n",
    "with open(os.path.join(log_dir, metadata_name), 'w') as f:\n",
    "    f.write('word' + '\\t' + 'vol_lv' + '\\t' + 'count' + '\\n')\n",
    "    for i, row in pd_wv.iterrows():\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(row.words, round(math.log(row.counts, 10)), row.counts))\n",
    "        embedding[i] = row.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5835, 100)\n"
     ]
    }
   ],
   "source": [
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ./models/embedding_log/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "embeddings_vectors = embedding\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Create some variables.\n",
    "emb = tf.compat.v1.Variable(embeddings_vectors, name='word_embeddings')\n",
    "\n",
    "# Add an op to initialize the variable.\n",
    "init_op = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables and save the\n",
    "# variables to disk.\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, os.path.join(log_dir, \"model.ckpt\"))\n",
    "    print(\"Model saved in path: %s\" % save_path)\n",
    "    \n",
    "    # Set up config\n",
    "    config = projector.ProjectorConfig()\n",
    "    # One can add multiple embeddings.\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = emb.name\n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    embedding.metadata_path = metadata_name\n",
    "    # Saves a config file that TensorBoard will read during startup.\n",
    "#     projector.visualize_embeddings(log_dir, config)\n",
    "projector.visualize_embeddings(tf.compat.v1.summary.FileWriter(log_dir), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir ./models/embedding_log/\n",
    "\n",
    "# %tensorboard dev upload --logdir \\\n",
    "#     './models/embedding_log/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kill 4371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Self-diagnosis script for TensorBoard.\n",
    "\n",
    "Instructions: Save this script to your local machine, then execute it in\n",
    "the same environment (virtualenv, Conda, etc.) from which you normally\n",
    "run TensorBoard. Read the output and follow the directions.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# This script may only depend on the Python standard library. It is not\n",
    "# built with Bazel and should not assume any third-party dependencies.\n",
    "import collections\n",
    "import errno\n",
    "import functools\n",
    "import hashlib\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "import pipes\n",
    "import shlex\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "import textwrap\n",
    "import traceback\n",
    "\n",
    "\n",
    "# A *check* is a function (of no arguments) that performs a diagnostic,\n",
    "# writes log messages, and optionally yields suggestions. Each check\n",
    "# runs in isolation; exceptions will be caught and reported.\n",
    "CHECKS = []\n",
    "\n",
    "\n",
    "# A suggestion to the end user.\n",
    "#   headline (str): A short description, like \"Turn it off and on\n",
    "#     again\". Should be imperative with no trailing punctuation. May\n",
    "#     contain inline Markdown.\n",
    "#   description (str): A full enumeration of the steps that the user\n",
    "#     should take to accept the suggestion. Within this string, prose\n",
    "#     should be formatted with `reflow`. May contain Markdown.\n",
    "Suggestion = collections.namedtuple(\"Suggestion\", (\"headline\", \"description\"))\n",
    "\n",
    "\n",
    "def check(fn):\n",
    "    \"\"\"Decorator to register a function as a check.\n",
    "\n",
    "    Checks are run in the order in which they are registered.\n",
    "\n",
    "    Args:\n",
    "      fn: A function that takes no arguments and either returns `None` or\n",
    "        returns a generator of `Suggestion`s. (The ability to return\n",
    "        `None` is to work around the awkwardness of defining empty\n",
    "        generator functions in Python.)\n",
    "\n",
    "    Returns:\n",
    "      A wrapped version of `fn` that returns a generator of `Suggestion`s.\n",
    "    \"\"\"\n",
    "\n",
    "    @functools.wraps(fn)\n",
    "    def wrapper():\n",
    "        result = fn()\n",
    "        return iter(()) if result is None else result\n",
    "\n",
    "    CHECKS.append(wrapper)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def reflow(paragraph):\n",
    "    return textwrap.fill(textwrap.dedent(paragraph).strip())\n",
    "\n",
    "\n",
    "def pip(args):\n",
    "    \"\"\"Invoke command-line Pip with the specified args.\n",
    "\n",
    "    Returns:\n",
    "      A bytestring containing the output of Pip.\n",
    "    \"\"\"\n",
    "    # Suppress the Python 2.7 deprecation warning.\n",
    "    PYTHONWARNINGS_KEY = \"PYTHONWARNINGS\"\n",
    "    old_pythonwarnings = os.environ.get(PYTHONWARNINGS_KEY)\n",
    "    new_pythonwarnings = \"%s%s\" % (\n",
    "        \"ignore:DEPRECATION\",\n",
    "        \",%s\" % old_pythonwarnings if old_pythonwarnings else \"\",\n",
    "    )\n",
    "    command = [sys.executable, \"-m\", \"pip\", \"--disable-pip-version-check\"]\n",
    "    command.extend(args)\n",
    "    try:\n",
    "        os.environ[PYTHONWARNINGS_KEY] = new_pythonwarnings\n",
    "        return subprocess.check_output(command)\n",
    "    finally:\n",
    "        if old_pythonwarnings is None:\n",
    "            del os.environ[PYTHONWARNINGS_KEY]\n",
    "        else:\n",
    "            os.environ[PYTHONWARNINGS_KEY] = old_pythonwarnings\n",
    "\n",
    "\n",
    "def which(name):\n",
    "    \"\"\"Return the path to a binary, or `None` if it's not on the path.\n",
    "\n",
    "    Returns:\n",
    "      A bytestring.\n",
    "    \"\"\"\n",
    "    binary = \"where\" if os.name == \"nt\" else \"which\"\n",
    "    try:\n",
    "        return subprocess.check_output([binary, name])\n",
    "    except subprocess.CalledProcessError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def sgetattr(attr, default):\n",
    "    \"\"\"Get an attribute off the `socket` module, or use a default.\"\"\"\n",
    "    sentinel = object()\n",
    "    result = getattr(socket, attr, sentinel)\n",
    "    if result is sentinel:\n",
    "        print(\"socket.%s does not exist\" % attr)\n",
    "        return default\n",
    "    else:\n",
    "        print(\"socket.%s = %r\" % (attr, result))\n",
    "        return result\n",
    "\n",
    "\n",
    "@check\n",
    "def autoidentify():\n",
    "    \"\"\"Print the Git hash of this version of `diagnose_tensorboard.py`.\n",
    "\n",
    "    Given this hash, use `git cat-file blob HASH` to recover the\n",
    "    relevant version of the script.\n",
    "    \"\"\"\n",
    "    module = sys.modules[__name__]\n",
    "    try:\n",
    "        source = inspect.getsource(module).encode(\"utf-8\")\n",
    "    except TypeError:\n",
    "        logging.info(\"diagnose_tensorboard.py source unavailable\")\n",
    "    else:\n",
    "        # Git inserts a length-prefix before hashing; cf. `git-hash-object`.\n",
    "        blob = b\"blob %d\\0%s\" % (len(source), source)\n",
    "        hash = hashlib.sha1(blob).hexdigest()\n",
    "        logging.info(\"diagnose_tensorboard.py version %s\", hash)\n",
    "\n",
    "\n",
    "@check\n",
    "def general():\n",
    "    logging.info(\"sys.version_info: %s\", sys.version_info)\n",
    "    logging.info(\"os.name: %s\", os.name)\n",
    "    na = type(\"N/A\", (object,), {\"__repr__\": lambda self: \"N/A\"})\n",
    "    logging.info(\n",
    "        \"os.uname(): %r\",\n",
    "        getattr(os, \"uname\", na)(),\n",
    "    )\n",
    "    logging.info(\n",
    "        \"sys.getwindowsversion(): %r\",\n",
    "        getattr(sys, \"getwindowsversion\", na)(),\n",
    "    )\n",
    "\n",
    "\n",
    "@check\n",
    "def package_management():\n",
    "    conda_meta = os.path.join(sys.prefix, \"conda-meta\")\n",
    "    logging.info(\"has conda-meta: %s\", os.path.exists(conda_meta))\n",
    "    logging.info(\"$VIRTUAL_ENV: %r\", os.environ.get(\"VIRTUAL_ENV\"))\n",
    "\n",
    "\n",
    "@check\n",
    "def installed_packages():\n",
    "    freeze = pip([\"freeze\", \"--all\"]).decode(\"utf-8\").splitlines()\n",
    "    packages = {line.split(\"==\")[0]: line for line in freeze}\n",
    "    packages_set = frozenset(packages)\n",
    "\n",
    "    # For each of the following families, expect exactly one package to be\n",
    "    # installed.\n",
    "    expect_unique = [\n",
    "        frozenset(\n",
    "            [\n",
    "                \"tensorboard\",\n",
    "                \"tb-nightly\",\n",
    "                \"tensorflow-tensorboard\",\n",
    "            ]\n",
    "        ),\n",
    "        frozenset(\n",
    "            [\n",
    "                \"tensorflow\",\n",
    "                \"tensorflow-gpu\",\n",
    "                \"tf-nightly\",\n",
    "                \"tf-nightly-2.0-preview\",\n",
    "                \"tf-nightly-gpu\",\n",
    "                \"tf-nightly-gpu-2.0-preview\",\n",
    "            ]\n",
    "        ),\n",
    "        frozenset(\n",
    "            [\n",
    "                \"tensorflow-estimator\",\n",
    "                \"tensorflow-estimator-2.0-preview\",\n",
    "                \"tf-estimator-nightly\",\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    found_conflict = False\n",
    "    for family in expect_unique:\n",
    "        actual = family & packages_set\n",
    "        for package in actual:\n",
    "            logging.info(\"installed: %s\", packages[package])\n",
    "        if len(actual) == 0:\n",
    "            logging.warning(\"no installation among: %s\", sorted(family))\n",
    "        elif len(actual) > 1:\n",
    "            logging.warning(\"conflicting installations: %s\", sorted(actual))\n",
    "            found_conflict = True\n",
    "\n",
    "    if found_conflict:\n",
    "        preamble = reflow(\n",
    "            \"\"\"\n",
    "            Conflicting package installations found. Depending on the order\n",
    "            of installations and uninstallations, behavior may be undefined.\n",
    "            Please uninstall ALL versions of TensorFlow and TensorBoard,\n",
    "            then reinstall ONLY the desired version of TensorFlow, which\n",
    "            will transitively pull in the proper version of TensorBoard. (If\n",
    "            you use TensorBoard without TensorFlow, just reinstall the\n",
    "            appropriate version of TensorBoard directly.)\n",
    "            \"\"\"\n",
    "        )\n",
    "        packages_to_uninstall = sorted(\n",
    "            frozenset().union(*expect_unique) & packages_set\n",
    "        )\n",
    "        commands = [\n",
    "            \"pip uninstall %s\" % \" \".join(packages_to_uninstall),\n",
    "            \"pip install tensorflow  # or `tensorflow-gpu`, or `tf-nightly`, ...\",\n",
    "        ]\n",
    "        message = \"%s\\n\\nNamely:\\n\\n%s\" % (\n",
    "            preamble,\n",
    "            \"\\n\".join(\"\\t%s\" % c for c in commands),\n",
    "        )\n",
    "        yield Suggestion(\"Fix conflicting installations\", message)\n",
    "\n",
    "    wit_version = packages.get(\"tensorboard-plugin-wit\")\n",
    "    if wit_version == \"tensorboard-plugin-wit==1.6.0.post2\":\n",
    "        # This is only incompatible with TensorBoard prior to 2.2.0, but\n",
    "        # we just issue a blanket warning so that we don't have to pull\n",
    "        # in a `pkg_resources` dep to parse the version.\n",
    "        preamble = reflow(\n",
    "            \"\"\"\n",
    "            Versions of the What-If Tool (`tensorboard-plugin-wit`)\n",
    "            prior to 1.6.0.post3 are incompatible with some versions of\n",
    "            TensorBoard. Please upgrade this package to the latest\n",
    "            version to resolve any startup errors:\n",
    "            \"\"\"\n",
    "        )\n",
    "        command = \"pip install -U tensorboard-plugin-wit\"\n",
    "        message = \"%s\\n\\n\\t%s\" % (preamble, command)\n",
    "        yield Suggestion(\"Upgrade `tensorboard-plugin-wit`\", message)\n",
    "\n",
    "\n",
    "@check\n",
    "def tensorboard_python_version():\n",
    "    from tensorboard import version\n",
    "\n",
    "    logging.info(\"tensorboard.version.VERSION: %r\", version.VERSION)\n",
    "\n",
    "\n",
    "@check\n",
    "def tensorflow_python_version():\n",
    "    import tensorflow as tf\n",
    "\n",
    "    logging.info(\"tensorflow.__version__: %r\", tf.__version__)\n",
    "    logging.info(\"tensorflow.__git_version__: %r\", tf.__git_version__)\n",
    "\n",
    "\n",
    "@check\n",
    "def tensorboard_binary_path():\n",
    "    logging.info(\"which tensorboard: %r\", which(\"tensorboard\"))\n",
    "\n",
    "\n",
    "@check\n",
    "def addrinfos():\n",
    "    sgetattr(\"has_ipv6\", None)\n",
    "    family = sgetattr(\"AF_UNSPEC\", 0)\n",
    "    socktype = sgetattr(\"SOCK_STREAM\", 0)\n",
    "    protocol = 0\n",
    "    flags_loopback = sgetattr(\"AI_ADDRCONFIG\", 0)\n",
    "    flags_wildcard = sgetattr(\"AI_PASSIVE\", 0)\n",
    "\n",
    "    hints_loopback = (family, socktype, protocol, flags_loopback)\n",
    "    infos_loopback = socket.getaddrinfo(None, 0, *hints_loopback)\n",
    "    print(\"Loopback flags: %r\" % (flags_loopback,))\n",
    "    print(\"Loopback infos: %r\" % (infos_loopback,))\n",
    "\n",
    "    hints_wildcard = (family, socktype, protocol, flags_wildcard)\n",
    "    infos_wildcard = socket.getaddrinfo(None, 0, *hints_wildcard)\n",
    "    print(\"Wildcard flags: %r\" % (flags_wildcard,))\n",
    "    print(\"Wildcard infos: %r\" % (infos_wildcard,))\n",
    "\n",
    "\n",
    "@check\n",
    "def readable_fqdn():\n",
    "    # May raise `UnicodeDecodeError` for non-ASCII hostnames:\n",
    "    # https://github.com/tensorflow/tensorboard/issues/682\n",
    "    try:\n",
    "        logging.info(\"socket.getfqdn(): %r\", socket.getfqdn())\n",
    "    except UnicodeDecodeError as e:\n",
    "        try:\n",
    "            binary_hostname = subprocess.check_output([\"hostname\"]).strip()\n",
    "        except subprocess.CalledProcessError:\n",
    "            binary_hostname = b\"<unavailable>\"\n",
    "        is_non_ascii = not all(\n",
    "            0x20\n",
    "            <= (ord(c) if not isinstance(c, int) else c)\n",
    "            <= 0x7E  # Python 2\n",
    "            for c in binary_hostname\n",
    "        )\n",
    "        if is_non_ascii:\n",
    "            message = reflow(\n",
    "                \"\"\"\n",
    "                Your computer's hostname, %r, contains bytes outside of the\n",
    "                printable ASCII range. Some versions of Python have trouble\n",
    "                working with such names (https://bugs.python.org/issue26227).\n",
    "                Consider changing to a hostname that only contains printable\n",
    "                ASCII bytes.\n",
    "                \"\"\"\n",
    "                % (binary_hostname,)\n",
    "            )\n",
    "            yield Suggestion(\"Use an ASCII hostname\", message)\n",
    "        else:\n",
    "            message = reflow(\n",
    "                \"\"\"\n",
    "                Python can't read your computer's hostname, %r. This can occur\n",
    "                if the hostname contains non-ASCII bytes\n",
    "                (https://bugs.python.org/issue26227). Consider changing your\n",
    "                hostname, rebooting your machine, and rerunning this diagnosis\n",
    "                script to see if the problem is resolved.\n",
    "                \"\"\"\n",
    "                % (binary_hostname,)\n",
    "            )\n",
    "            yield Suggestion(\"Use a simpler hostname\", message)\n",
    "        raise e\n",
    "\n",
    "\n",
    "@check\n",
    "def stat_tensorboardinfo():\n",
    "    # We don't use `manager._get_info_dir`, because (a) that requires\n",
    "    # TensorBoard, and (b) that creates the directory if it doesn't exist.\n",
    "    path = os.path.join(tempfile.gettempdir(), \".tensorboard-info\")\n",
    "    logging.info(\"directory: %s\", path)\n",
    "    try:\n",
    "        stat_result = os.stat(path)\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.ENOENT:\n",
    "            # No problem; this is just fine.\n",
    "            logging.info(\".tensorboard-info directory does not exist\")\n",
    "            return\n",
    "        else:\n",
    "            raise\n",
    "    logging.info(\"os.stat(...): %r\", stat_result)\n",
    "    logging.info(\"mode: 0o%o\", stat_result.st_mode)\n",
    "    if stat_result.st_mode & 0o777 != 0o777:\n",
    "        preamble = reflow(\n",
    "            \"\"\"\n",
    "            The \".tensorboard-info\" directory was created by an old version\n",
    "            of TensorBoard, and its permissions are not set correctly; see\n",
    "            issue #2010. Change that directory to be world-accessible (may\n",
    "            require superuser privilege):\n",
    "            \"\"\"\n",
    "        )\n",
    "        # This error should only appear on Unices, so it's okay to use\n",
    "        # Unix-specific utilities and shell syntax.\n",
    "        quote = getattr(shlex, \"quote\", None) or pipes.quote  # Python <3.3\n",
    "        command = \"chmod 777 %s\" % quote(path)\n",
    "        message = \"%s\\n\\n\\t%s\" % (preamble, command)\n",
    "        yield Suggestion('Fix permissions on \"%s\"' % path, message)\n",
    "\n",
    "\n",
    "@check\n",
    "def source_trees_without_genfiles():\n",
    "    roots = list(sys.path)\n",
    "    if \"\" not in roots:\n",
    "        # Catch problems that would occur in a Python interactive shell\n",
    "        # (where `\"\"` is prepended to `sys.path`) but not when\n",
    "        # `diagnose_tensorboard.py` is run as a standalone script.\n",
    "        roots.insert(0, \"\")\n",
    "\n",
    "    def has_tensorboard(root):\n",
    "        return os.path.isfile(os.path.join(root, \"tensorboard\", \"__init__.py\"))\n",
    "\n",
    "    def has_genfiles(root):\n",
    "        sample_genfile = os.path.join(\"compat\", \"proto\", \"summary_pb2.py\")\n",
    "        return os.path.isfile(os.path.join(root, \"tensorboard\", sample_genfile))\n",
    "\n",
    "    def is_bad(root):\n",
    "        return has_tensorboard(root) and not has_genfiles(root)\n",
    "\n",
    "    tensorboard_roots = [root for root in roots if has_tensorboard(root)]\n",
    "    bad_roots = [root for root in roots if is_bad(root)]\n",
    "\n",
    "    logging.info(\n",
    "        \"tensorboard_roots (%d): %r; bad_roots (%d): %r\",\n",
    "        len(tensorboard_roots),\n",
    "        tensorboard_roots,\n",
    "        len(bad_roots),\n",
    "        bad_roots,\n",
    "    )\n",
    "\n",
    "    if bad_roots:\n",
    "        if bad_roots == [\"\"]:\n",
    "            message = reflow(\n",
    "                \"\"\"\n",
    "                Your current directory contains a `tensorboard` Python package\n",
    "                that does not include generated files. This can happen if your\n",
    "                current directory includes the TensorBoard source tree (e.g.,\n",
    "                you are in the TensorBoard Git repository). Consider changing\n",
    "                to a different directory.\n",
    "                \"\"\"\n",
    "            )\n",
    "        else:\n",
    "            preamble = reflow(\n",
    "                \"\"\"\n",
    "                Your Python path contains a `tensorboard` package that does\n",
    "                not include generated files. This can happen if your current\n",
    "                directory includes the TensorBoard source tree (e.g., you are\n",
    "                in the TensorBoard Git repository). The following directories\n",
    "                from your Python path may be problematic:\n",
    "                \"\"\"\n",
    "            )\n",
    "            roots = []\n",
    "            realpaths_seen = set()\n",
    "            for root in bad_roots:\n",
    "                label = repr(root) if root else \"current directory\"\n",
    "                realpath = os.path.realpath(root)\n",
    "                if realpath in realpaths_seen:\n",
    "                    # virtualenvs on Ubuntu install to both `lib` and `local/lib`;\n",
    "                    # explicitly call out such duplicates to avoid confusion.\n",
    "                    label += \" (duplicate underlying directory)\"\n",
    "                realpaths_seen.add(realpath)\n",
    "                roots.append(label)\n",
    "            message = \"%s\\n\\n%s\" % (\n",
    "                preamble,\n",
    "                \"\\n\".join(\"  - %s\" % s for s in roots),\n",
    "            )\n",
    "        yield Suggestion(\n",
    "            \"Avoid `tensorboard` packages without genfiles\", message\n",
    "        )\n",
    "\n",
    "\n",
    "# Prefer to include this check last, as its output is long.\n",
    "@check\n",
    "def full_pip_freeze():\n",
    "    logging.info(\n",
    "        \"pip freeze --all:\\n%s\", pip([\"freeze\", \"--all\"]).decode(\"utf-8\")\n",
    "    )\n",
    "\n",
    "\n",
    "def set_up_logging():\n",
    "    # Manually install handlers to prevent TensorFlow from stomping the\n",
    "    # default configuration if it's imported:\n",
    "    # https://github.com/tensorflow/tensorflow/issues/28147\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_up_logging()\n",
    "\n",
    "    print(\"### Diagnostics\")\n",
    "    print()\n",
    "\n",
    "    print(\"<details>\")\n",
    "    print(\"<summary>Diagnostics output</summary>\")\n",
    "    print()\n",
    "\n",
    "    markdown_code_fence = \"``````\"  # seems likely to be sufficient\n",
    "    print(markdown_code_fence)\n",
    "    suggestions = []\n",
    "    for (i, check) in enumerate(CHECKS):\n",
    "        if i > 0:\n",
    "            print()\n",
    "        print(\"--- check: %s\" % check.__name__)\n",
    "        try:\n",
    "            suggestions.extend(check())\n",
    "        except Exception:\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "            pass\n",
    "    print(markdown_code_fence)\n",
    "    print()\n",
    "    print(\"</details>\")\n",
    "\n",
    "    for suggestion in suggestions:\n",
    "        print()\n",
    "        print(\"### Suggestion: %s\" % suggestion.headline)\n",
    "        print()\n",
    "        print(suggestion.description)\n",
    "\n",
    "    print()\n",
    "    print(\"### Next steps\")\n",
    "    print()\n",
    "    if suggestions:\n",
    "        print(\n",
    "            reflow(\n",
    "                \"\"\"\n",
    "                Please try each suggestion enumerated above to determine whether\n",
    "                it solves your problem. If none of these suggestions works,\n",
    "                please copy ALL of the above output, including the lines\n",
    "                containing only backticks, into your GitHub issue or comment. Be\n",
    "                sure to redact any sensitive information.\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            reflow(\n",
    "                \"\"\"\n",
    "                No action items identified. Please copy ALL of the above output,\n",
    "                including the lines containing only backticks, into your GitHub\n",
    "                issue or comment. Be sure to redact any sensitive information.\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
